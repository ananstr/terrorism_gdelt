{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b964981c",
   "metadata": {},
   "source": [
    "# 0. Imports and installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6d5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars\n",
    "# !pip install pyahocorasick\n",
    "# !pip install httpx trafilatura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546643ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import polars as pl\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from urllib.parse import urljoin\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data_dir = 'data'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "parquet_dir = os.path.join(data_dir, \"filtered_parquets\")\n",
    "os.makedirs(parquet_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb617d1b",
   "metadata": {},
   "source": [
    "# 1. Obtaining the data\n",
    "\n",
    "To obtain the data we access the GDELT 1.0 Event Database -- a repository where they store a dataset (in csv format) for every day since January 1st, 1979 with news articles from the whole world. This is updated daily and each file contains tens of thousands of news articles (their urls). \n",
    "\n",
    "In the pipeline below, we access the archive url and download the files for the period going from January 1st, 2020 to June 6th, 2021. The reason for this is that our terrorism dataset source only contains data up to June 2021 and we limited our period to 18 months because of the scale of the GDELT Database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfa8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDELT events archive URL\n",
    "base_url = \"http://data.gdeltproject.org/events/\"\n",
    "\n",
    "# get the list of ZIP files\n",
    "response = requests.get(base_url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "start_period = '202001'\n",
    "end_period = '202106'\n",
    "\n",
    "zip_links = [\n",
    "    a['href']\n",
    "    for a in soup.find_all('a', href=True)\n",
    "    if a['href'].endswith('.zip') and start_period <= a['href'][:6] <= end_period\n",
    "]\n",
    "\n",
    "# download and extract each ZIP file\n",
    "def download_and_extract(link):\n",
    "    zip_url = urljoin(base_url, link)\n",
    "    try:\n",
    "        r = requests.get(zip_url, stream=True, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        with BytesIO() as tmp_buffer:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    tmp_buffer.write(chunk)\n",
    "            tmp_buffer.seek(0)\n",
    "            with ZipFile(tmp_buffer) as z:\n",
    "                z.extractall(data_dir)\n",
    "    except Exception as e:\n",
    "        print(f'Failed: {zip_url} - {e}')\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    list(tqdm(executor.map(download_and_extract, zip_links), total=len(zip_links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a521ea",
   "metadata": {},
   "source": [
    "Below is our reference dictionary of the columns contained in the GDELT csvs, as they are unnamed in the files. We decide to keep the following:\n",
    "* Month, Year - format YYYYMMM\n",
    "* Year\n",
    "* Event Code\n",
    "* Quad Class\n",
    "* Goldstein Scale\n",
    "* Average Tone\n",
    "* Actor 1 state code\n",
    "* Actor 3 state code\n",
    "* Country - to filter by 'US'\n",
    "* State\n",
    "* Date\n",
    "* URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column_dict = {\n",
    "#     0: 'event_id',\n",
    "#     1: 'SQLDATE',\n",
    "#     2: 'MonthYear',\n",
    "#     3: 'Year',\n",
    "#     4: 'FractionDate',\n",
    "#     5: 'Actor1Code',\n",
    "#     6: 'Actor1Name',\n",
    "#     7: 'Actor1CountryCode',\n",
    "#     8: 'Actor1KnownGroupCode',\n",
    "#     9: 'Actor1EthnicCode',\n",
    "#     10: 'Actor1Religion1Code',\n",
    "#     11: 'Actor1Religion2Code',\n",
    "#     12: 'Actor1Type1Code',\n",
    "#     13: 'Actor1Type2Code',\n",
    "#     14: 'Actor1Type3Code',\n",
    "#     15: 'Actor2Code',\n",
    "#     16: 'Actor2Name',\n",
    "#     17: 'Actor2CountryCode',\n",
    "#     18: 'Actor2KnownGroupCode',\n",
    "#     19: 'Actor2EthnicCode',\n",
    "#     20: 'Actor2Religion1Code',\n",
    "#     21: 'Actor2Religion2Code',\n",
    "#     22: 'Actor2Type1Code',\n",
    "#     23: 'Actor2Type2Code',\n",
    "#     24: 'Actor2Type3Code',\n",
    "#     25: 'IsRootEvent',\n",
    "#     26: 'EventCode',\n",
    "#     27: 'EventBaseCode',\n",
    "#     28: 'EventRootCode',\n",
    "#     29: 'QuadClass',\n",
    "#     30: 'GoldsteinScale',\n",
    "#     31: 'NumMentions',\n",
    "#     32: 'NumSources',\n",
    "#     33: 'NumArticles',\n",
    "#     34: 'AvgTone',\n",
    "#     35: 'Actor1Geo_Type',\n",
    "#     36: 'Actor1Geo_FullName',\n",
    "#     37: 'Actor1Geo_CountryCode',\n",
    "#     38: 'Actor1Geo_ADM1Code',\n",
    "#     39: 'Actor1Geo_Lat',\n",
    "#     40: 'Actor1Geo_Long',\n",
    "#     41: 'Actor1Geo_FeatureID',\n",
    "#     42: 'Actor2Geo_Type',\n",
    "#     43: 'Actor2Geo_FullName',\n",
    "#     44: 'Actor2Geo_CountryCode',\n",
    "#     45: 'Actor2Geo_ADM1Code',\n",
    "#     46: 'Actor2Geo_Lat',\n",
    "#     47: 'Actor2Geo_Long',\n",
    "#     48: 'Actor2Geo_FeatureID',\n",
    "#     49: 'ActionGeo_Type',\n",
    "#     50: 'ActionGeo_FullName',\n",
    "#     51: 'ActionGeo_CountryCode',\n",
    "#     52: 'ActionGeo_ADM1Code',\n",
    "#     53: 'ActionGeo_Lat',\n",
    "#     54: 'ActionGeo_Long',\n",
    "#     55: 'ActionGeo_FeatureID',\n",
    "#     56: 'date',\n",
    "#     57: 'url',\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66295035",
   "metadata": {},
   "source": [
    "Next, we process the csv one by one. We upload them, keep the coulmns of interest, filter the rows belonging to the US, and drop duplicates. We then save each file as a parquet, as it is a more efficient file format. Doing it file by file allows us to make the process more efficient as well as to keep separate files for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d5ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV files: 100%|██████████| 547/547 [01:17<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been processed and saved as Parquet files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.CSV')]\n",
    "\n",
    "# df_us = pd.DataFrame()\n",
    "\n",
    "# COLUMNS TO LOAD\n",
    "# indexes\n",
    "columns_to_load = [2, 3, 26, 29, 30, 34, 38, 45, 51, 52, 56, 57]\n",
    "\n",
    "# dictionary with parquet naming of the columns\n",
    "column_dict = {\n",
    "    'column_3': 'month_year',\n",
    "    'column_4': 'year',\n",
    "    'column_27': 'event_code',\n",
    "    'column_30': 'quad_class',\n",
    "    'column_31': 'goldstein_scale',\n",
    "    'column_35': 'avg_tone',\n",
    "    'column_39': 'actor1_statecode',\n",
    "    'column_46': 'actor2_statecode',\n",
    "    'column_52': 'country',\n",
    "    'column_53': 'state',\n",
    "    'column_57': 'date',\n",
    "    'column_58': 'url',  \n",
    "}\n",
    "\n",
    "\n",
    "parquet_dir = os.path.join(data_dir, \"filtered_parquets\")\n",
    "os.makedirs(parquet_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over CSV files, format the DF, and extract title from URL\n",
    "for csv_file in tqdm(csv_files, desc=\"Processing CSV files\"):\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "\n",
    "    df = pl.read_csv(\n",
    "        file_path,\n",
    "        separator='\\t',\n",
    "        columns=columns_to_load,\n",
    "        has_header=False,\n",
    "        null_values=['---', 'X', ''],  # handle potential null values\n",
    "        schema_overrides={'column_27': pl.Utf8},  \n",
    "        ignore_errors=False  \n",
    "    ).rename(column_dict)\n",
    "\n",
    "    # convert event_code to Int64 after cleaning\n",
    "    df = df.with_columns(\n",
    "        pl.col('event_code').str.replace_all(r'\\D', '')  \n",
    "        .cast(pl.Int64, strict=False)  \n",
    "    )\n",
    "\n",
    "    # keep only US + remove duplicates\n",
    "    df_lazy = df.lazy() \n",
    "    del df\n",
    "    df_us = df_lazy.filter(pl.col('country') == 'US').drop('country').unique().collect()\n",
    "\n",
    "    parquet_path = os.path.join(parquet_dir, csv_file.replace(\".CSV\", \".parquet\"))\n",
    "    df_us.write_parquet(parquet_path)\n",
    "\n",
    "    del df_us\n",
    "\n",
    "print(\"All CSV files have been processed and saved as Parquet files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b33a9",
   "metadata": {},
   "source": [
    "Finally, we create a joint dataset with the whole time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d286da",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_files = [os.path.join(parquet_dir, f) for f in os.listdir(parquet_dir) if f.endswith('.parquet')]\n",
    "df_all = pl.concat([pl.read_parquet(f) for f in parquet_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7eabb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>month_year</th><th>year</th><th>event_code</th><th>quad_class</th><th>goldstein_scale</th><th>avg_tone</th><th>actor1_statecode</th><th>actor2_statecode</th><th>state</th><th>date</th><th>url</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>192001</td><td>1920</td><td>43</td><td>1</td><td>2.8</td><td>-3.924092</td><td>null</td><td>&quot;USVA&quot;</td><td>&quot;USVA&quot;</td><td>20200101</td><td>&quot;https://www.rockymounttelegram…</td></tr><tr><td>192001</td><td>1920</td><td>20</td><td>1</td><td>3.0</td><td>-1.827875</td><td>&quot;USCA&quot;</td><td>&quot;USCA&quot;</td><td>&quot;USCA&quot;</td><td>20200101</td><td>&quot;https://www.sfchronicle.com/bu…</td></tr><tr><td>192001</td><td>1920</td><td>10</td><td>1</td><td>0.0</td><td>0.0</td><td>&quot;USCA&quot;</td><td>&quot;USCA&quot;</td><td>&quot;USCA&quot;</td><td>20200101</td><td>&quot;https://www.49ers.com/about-us…</td></tr><tr><td>192001</td><td>1920</td><td>190</td><td>4</td><td>-10.0</td><td>-2.040816</td><td>&quot;USDC&quot;</td><td>&quot;USDC&quot;</td><td>&quot;USDC&quot;</td><td>20200101</td><td>&quot;https://www.newsweek.com/giuli…</td></tr><tr><td>192001</td><td>1920</td><td>173</td><td>4</td><td>-5.0</td><td>-8.445946</td><td>null</td><td>&quot;USCA&quot;</td><td>&quot;USCA&quot;</td><td>20200101</td><td>&quot;https://www.dailyrepublic.com/…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌────────────┬──────┬────────────┬────────────┬───┬──────────────┬───────┬──────────┬──────────────┐\n",
       "│ month_year ┆ year ┆ event_code ┆ quad_class ┆ … ┆ actor2_state ┆ state ┆ date     ┆ url          │\n",
       "│ ---        ┆ ---  ┆ ---        ┆ ---        ┆   ┆ code         ┆ ---   ┆ ---      ┆ ---          │\n",
       "│ i64        ┆ i64  ┆ i64        ┆ i64        ┆   ┆ ---          ┆ str   ┆ i64      ┆ str          │\n",
       "│            ┆      ┆            ┆            ┆   ┆ str          ┆       ┆          ┆              │\n",
       "╞════════════╪══════╪════════════╪════════════╪═══╪══════════════╪═══════╪══════════╪══════════════╡\n",
       "│ 192001     ┆ 1920 ┆ 43         ┆ 1          ┆ … ┆ USVA         ┆ USVA  ┆ 20200101 ┆ https://www. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ rockymountte │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ legram…      │\n",
       "│ 192001     ┆ 1920 ┆ 20         ┆ 1          ┆ … ┆ USCA         ┆ USCA  ┆ 20200101 ┆ https://www. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ sfchronicle. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ com/bu…      │\n",
       "│ 192001     ┆ 1920 ┆ 10         ┆ 1          ┆ … ┆ USCA         ┆ USCA  ┆ 20200101 ┆ https://www. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ 49ers.com/ab │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ out-us…      │\n",
       "│ 192001     ┆ 1920 ┆ 190        ┆ 4          ┆ … ┆ USDC         ┆ USDC  ┆ 20200101 ┆ https://www. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ newsweek.com │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ /giuli…      │\n",
       "│ 192001     ┆ 1920 ┆ 173        ┆ 4          ┆ … ┆ USCA         ┆ USCA  ┆ 20200101 ┆ https://www. │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ dailyrepubli │\n",
       "│            ┆      ┆            ┆            ┆   ┆              ┆       ┆          ┆ c.com/…      │\n",
       "└────────────┴──────┴────────────┴────────────┴───┴──────────────┴───────┴──────────┴──────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36399138",
   "metadata": {},
   "source": [
    "The scale of the dataset is way to big - it has over 18 million rows and 34,000 news articles per day. Due to time and resource constraints we cannot process this, so we pick 5 news per state per day. It is a small number but it is the largest size we could choose to be able to properly run the code below without major time delays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458bfdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----BEFORE FILTERING----\n",
      "Total rows after cleaning: 18,792,604\n",
      "Average rows per day: 34,356\n",
      "\n",
      "----AFTER FILTERING----\n",
      "Total rows after filtering: 145,030\n",
      "Average rows per day: 265\n"
     ]
    }
   ],
   "source": [
    "print('----BEFORE FILTERING----')\n",
    "print(f\"Total rows after cleaning: {df_all.height:,}\")\n",
    "print('Average rows per day:', f\"{round(df_all.height / len(parquet_files)):,}\")\n",
    "\n",
    "rows_per_state_per_day = 5\n",
    "df_filtered = (\n",
    "    df_all\n",
    "    .group_by([\"state\", \"date\"], maintain_order=True)\n",
    "    .head(rows_per_state_per_day)  \n",
    ")\n",
    "\n",
    "print('\\n----AFTER FILTERING----')\n",
    "print(f\"Total rows after filtering: {df_filtered.height:,}\")\n",
    "print('Average rows per day:', f\"{round(df_filtered.height / len(parquet_files)):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2908bc",
   "metadata": {},
   "source": [
    "## 1.2. Extracting article title and body\n",
    "\n",
    "We extract the title and the body by scraping the url links in the GDELT dataset. This process is very long and not always successfull (text is extracted successfully in around 50% of the articles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d7f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import trafilatura\n",
    "import polars as pl\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up URLs from your Polars DF\n",
    "urls = df_filtered['url'].to_list()\n",
    "\n",
    "# Fetch function\n",
    "def fetch_article(url, timeout=15):\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/114.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        with httpx.Client(headers=headers, follow_redirects=True, timeout=timeout) as client:\n",
    "            response = client.get(url)\n",
    "            if response.status_code == 200:\n",
    "                html = response.text\n",
    "                article_text = trafilatura.extract(html)\n",
    "                metadata = trafilatura.extract_metadata(html)\n",
    "\n",
    "                title = getattr(metadata, \"title\", None) if metadata else None\n",
    "                if title is None and isinstance(metadata, dict):\n",
    "                    title = metadata.get(\"title\")\n",
    "\n",
    "                if article_text:\n",
    "                    return {\"url\": url, \"title\": title, \"full_text\": article_text}\n",
    "    except Exception:\n",
    "        pass\n",
    "    return {\"url\": url, \"title\": None, \"full_text\": None}\n",
    "\n",
    "# run concurrently and add results to a list\n",
    "results = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=32) as executor:\n",
    "    futures = {executor.submit(fetch_article, url): url for url in urls}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching\"):\n",
    "        results.append(future.result())\n",
    "\n",
    "# add to our dataframe\n",
    "df_results = pl.DataFrame(results)\n",
    "\n",
    "df_filtered = df_filtered.unique(subset=[\"url\"])\n",
    "df_results = df_results.unique(subset=[\"url\"])\n",
    "\n",
    "df_filtered = df_filtered.join(df_results, on=\"url\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4aacdb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news articles texts correctly extracted: 77,661\n"
     ]
    }
   ],
   "source": [
    "successful_extractions = df_filtered.select(pl.col(\"full_text\").n_unique()).item() - 1\n",
    "print(f'Number of news articles texts correctly extracted: {successful_extractions:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227dea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>state</th><th>date</th><th>month_year</th><th>year</th><th>event_code</th><th>quad_class</th><th>goldstein_scale</th><th>avg_tone</th><th>actor1_statecode</th><th>actor2_statecode</th><th>url</th><th>title</th><th>full_text</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;USMO&quot;</td><td>20210514</td><td>202105</td><td>2021</td><td>16</td><td>1</td><td>-2.0</td><td>-8.934073</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.natlawreview.com/a…</td><td>&quot;State of the Law for Business …</td><td>&quot;It’s been a year since COVID-1…</td></tr><tr><td>&quot;USMO&quot;</td><td>20210514</td><td>202105</td><td>2021</td><td>141</td><td>3</td><td>-6.5</td><td>-0.808625</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.kcur.org/health/20…</td><td>&quot;Medicaid Expansion Supporters …</td><td>&quot;A day after Missouri Gov. Mike…</td></tr><tr><td>&quot;USMO&quot;</td><td>20210529</td><td>202105</td><td>2021</td><td>13</td><td>1</td><td>0.4</td><td>-6.008584</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.dailystar.co.uk/ne…</td><td>&quot;Elderly woman sucker-punched t…</td><td>&quot;Elderly woman sucker-punched t…</td></tr><tr><td>&quot;USAR&quot;</td><td>20200207</td><td>202002</td><td>2020</td><td>16</td><td>1</td><td>-2.0</td><td>-8.0</td><td>&quot;USAR&quot;</td><td>null</td><td>&quot;https://www.houstonchronicle.c…</td><td>null</td><td>null</td></tr><tr><td>&quot;USNH&quot;</td><td>20201206</td><td>202012</td><td>2020</td><td>70</td><td>2</td><td>7.0</td><td>0.088106</td><td>&quot;USNH&quot;</td><td>&quot;USNH&quot;</td><td>&quot;https://www.fosters.com/story/…</td><td>&quot;Historically Speaking: Adventu…</td><td>&quot;Historically Speaking: Adventu…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌───────┬──────────┬────────────┬──────┬───┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ state ┆ date     ┆ month_year ┆ year ┆ … ┆ actor2_stat ┆ url         ┆ title       ┆ full_text   │\n",
       "│ ---   ┆ ---      ┆ ---        ┆ ---  ┆   ┆ ecode       ┆ ---         ┆ ---         ┆ ---         │\n",
       "│ str   ┆ i64      ┆ i64        ┆ i64  ┆   ┆ ---         ┆ str         ┆ str         ┆ str         │\n",
       "│       ┆          ┆            ┆      ┆   ┆ str         ┆             ┆             ┆             │\n",
       "╞═══════╪══════════╪════════════╪══════╪═══╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ USMO  ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ USMO        ┆ https://www ┆ State of    ┆ It’s been a │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ .natlawrevi ┆ the Law for ┆ year since  │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ ew.com/a…   ┆ Business …  ┆ COVID-1…    │\n",
       "│ USMO  ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ USMO        ┆ https://www ┆ Medicaid    ┆ A day after │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ .kcur.org/h ┆ Expansion   ┆ Missouri    │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ ealth/20…   ┆ Supporters  ┆ Gov. Mike…  │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆             ┆ …           ┆             │\n",
       "│ USMO  ┆ 20210529 ┆ 202105     ┆ 2021 ┆ … ┆ USMO        ┆ https://www ┆ Elderly     ┆ Elderly     │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ .dailystar. ┆ woman sucke ┆ woman sucke │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ co.uk/ne…   ┆ r-punched   ┆ r-punched   │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆             ┆ t…          ┆ t…          │\n",
       "│ USAR  ┆ 20200207 ┆ 202002     ┆ 2020 ┆ … ┆ null        ┆ https://www ┆ null        ┆ null        │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ .houstonchr ┆             ┆             │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ onicle.c…   ┆             ┆             │\n",
       "│ USNH  ┆ 20201206 ┆ 202012     ┆ 2020 ┆ … ┆ USNH        ┆ https://www ┆ Historicall ┆ Historicall │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ .fosters.co ┆ y Speaking: ┆ y Speaking: │\n",
       "│       ┆          ┆            ┆      ┆   ┆             ┆ m/story/…   ┆ Adventu…    ┆ Adventu…    │\n",
       "└───────┴──────────┴────────────┴──────┴───┴─────────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f85a9ea",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7bc91",
   "metadata": {},
   "source": [
    "## 2.1. Extracting States from the news text\n",
    "\n",
    "We extract the states from the news text by finding mentions to the state name, the capital, or the second and third cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2a8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.write_parquet(\"data/FILTERED_DATAFRAME.parquet\")\n",
    "# df_filtered = pl.read_parquet(\"data/FILTERED_DATAFRAME.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb64e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>state</th><th>date</th><th>month_year</th><th>year</th><th>event_code</th><th>quad_class</th><th>goldstein_scale</th><th>avg_tone</th><th>actor1_statecode</th><th>actor2_statecode</th><th>url</th><th>title</th><th>full_text</th></tr><tr><td>list[str]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>[&quot;WA&quot;, &quot;WI&quot;, … &quot;MA&quot;]</td><td>20210514</td><td>202105</td><td>2021</td><td>16</td><td>1</td><td>-2.0</td><td>-8.934073</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.natlawreview.com/a…</td><td>&quot;State of the Law for Business …</td><td>&quot;It’s been a year since COVID-1…</td></tr><tr><td>[&quot;KS&quot;, &quot;WA&quot;, &quot;MO&quot;]</td><td>20210514</td><td>202105</td><td>2021</td><td>141</td><td>3</td><td>-6.5</td><td>-0.808625</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.kcur.org/health/20…</td><td>&quot;Medicaid Expansion Supporters …</td><td>&quot;A day after Missouri Gov. Mike…</td></tr><tr><td>[&quot;NY&quot;, &quot;MO&quot;]</td><td>20210529</td><td>202105</td><td>2021</td><td>13</td><td>1</td><td>0.4</td><td>-6.008584</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.dailystar.co.uk/ne…</td><td>&quot;Elderly woman sucker-punched t…</td><td>&quot;Elderly woman sucker-punched t…</td></tr><tr><td>null</td><td>20200207</td><td>202002</td><td>2020</td><td>16</td><td>1</td><td>-2.0</td><td>-8.0</td><td>&quot;USAR&quot;</td><td>null</td><td>&quot;https://www.houstonchronicle.c…</td><td>null</td><td>null</td></tr><tr><td>[&quot;NY&quot;, &quot;DE&quot;, … &quot;MA&quot;]</td><td>20201206</td><td>202012</td><td>2020</td><td>70</td><td>2</td><td>7.0</td><td>0.088106</td><td>&quot;USNH&quot;</td><td>&quot;USNH&quot;</td><td>&quot;https://www.fosters.com/story/…</td><td>&quot;Historically Speaking: Adventu…</td><td>&quot;Historically Speaking: Adventu…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌────────────┬──────────┬────────────┬──────┬───┬────────────┬────────────┬────────────┬───────────┐\n",
       "│ state      ┆ date     ┆ month_year ┆ year ┆ … ┆ actor2_sta ┆ url        ┆ title      ┆ full_text │\n",
       "│ ---        ┆ ---      ┆ ---        ┆ ---  ┆   ┆ tecode     ┆ ---        ┆ ---        ┆ ---       │\n",
       "│ list[str]  ┆ i64      ┆ i64        ┆ i64  ┆   ┆ ---        ┆ str        ┆ str        ┆ str       │\n",
       "│            ┆          ┆            ┆      ┆   ┆ str        ┆            ┆            ┆           │\n",
       "╞════════════╪══════════╪════════════╪══════╪═══╪════════════╪════════════╪════════════╪═══════════╡\n",
       "│ [\"WA\",     ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ USMO       ┆ https://ww ┆ State of   ┆ It’s been │\n",
       "│ \"WI\", …    ┆          ┆            ┆      ┆   ┆            ┆ w.natlawre ┆ the Law    ┆ a year    │\n",
       "│ \"MA\"]      ┆          ┆            ┆      ┆   ┆            ┆ view.com/a ┆ for        ┆ since     │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ …          ┆ Business … ┆ COVID-1…  │\n",
       "│ [\"KS\",     ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ USMO       ┆ https://ww ┆ Medicaid   ┆ A day     │\n",
       "│ \"WA\",      ┆          ┆            ┆      ┆   ┆            ┆ w.kcur.org ┆ Expansion  ┆ after     │\n",
       "│ \"MO\"]      ┆          ┆            ┆      ┆   ┆            ┆ /health/20 ┆ Supporters ┆ Missouri  │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ …          ┆ …          ┆ Gov.      │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆            ┆            ┆ Mike…     │\n",
       "│ [\"NY\",     ┆ 20210529 ┆ 202105     ┆ 2021 ┆ … ┆ USMO       ┆ https://ww ┆ Elderly    ┆ Elderly   │\n",
       "│ \"MO\"]      ┆          ┆            ┆      ┆   ┆            ┆ w.dailysta ┆ woman suck ┆ woman suc │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ r.co.uk/ne ┆ er-punched ┆ ker-punch │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ …          ┆ t…         ┆ ed t…     │\n",
       "│ null       ┆ 20200207 ┆ 202002     ┆ 2020 ┆ … ┆ null       ┆ https://ww ┆ null       ┆ null      │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ w.houstonc ┆            ┆           │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ hronicle.c ┆            ┆           │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ …          ┆            ┆           │\n",
       "│ [\"NY\",     ┆ 20201206 ┆ 202012     ┆ 2020 ┆ … ┆ USNH       ┆ https://ww ┆ Historical ┆ Historica │\n",
       "│ \"DE\", …    ┆          ┆            ┆      ┆   ┆            ┆ w.fosters. ┆ ly         ┆ lly       │\n",
       "│ \"MA\"]      ┆          ┆            ┆      ┆   ┆            ┆ com/story/ ┆ Speaking:  ┆ Speaking: │\n",
       "│            ┆          ┆            ┆      ┆   ┆            ┆ …          ┆ Adventu…   ┆ Adventu…  │\n",
       "└────────────┴──────────┴────────────┴──────┴───┴────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_dict = { # CONTAINS STATE NAME + CAPITAL + 2nd AND 3rd LARGEST CITIES\n",
    "    'AL': ['Alabama', 'Montgomery', 'Birmingham', 'Mobile'],\n",
    "    'AK': ['Alaska', 'Juneau', 'Anchorage', 'Fairbanks'],\n",
    "    'AZ': ['Arizona', 'Phoenix', 'Tucson', 'Mesa'],\n",
    "    'AR': ['Arkansas', 'Little Rock', 'Fort Smith', 'Fayetteville'],\n",
    "    'CA': ['California', 'Sacramento', 'Los Angeles', 'San Diego'],\n",
    "    'CO': ['Colorado', 'Denver', 'Colorado Springs', 'Aurora'],\n",
    "    'CT': ['Connecticut', 'Hartford', 'Bridgeport', 'New Haven'],\n",
    "    'DE': ['Delaware', 'Dover', 'Wilmington', 'Newark'],\n",
    "    'FL': ['Florida', 'Tallahassee', 'Jacksonville', 'Miami'],\n",
    "    'GA': ['Georgia', 'Atlanta', 'Augusta', 'Columbus'],\n",
    "    'HI': ['Hawaii', 'Honolulu', 'Hilo', 'Kailua'],\n",
    "    'ID': ['Idaho', 'Boise', 'Meridian', 'Nampa'],\n",
    "    'IL': ['Illinois', 'Springfield', 'Chicago', 'Aurora'],\n",
    "    'IN': ['Indiana', 'Indianapolis', 'Fort Wayne', 'Evansville'],\n",
    "    'IA': ['Iowa', 'Des Moines', 'Cedar Rapids', 'Davenport'],\n",
    "    'KS': ['Kansas', 'Topeka', 'Wichita', 'Overland Park'],\n",
    "    'KY': ['Kentucky', 'Frankfort', 'Louisville', 'Lexington'],\n",
    "    'LA': ['Louisiana', 'Baton Rouge', 'New Orleans', 'Shreveport'],\n",
    "    'ME': ['Maine', 'Augusta', 'Portland', 'Lewiston'],\n",
    "    'MD': ['Maryland', 'Annapolis', 'Baltimore', 'Frederick'],\n",
    "    'MA': ['Massachusetts', 'Boston', 'Worcester', 'Springfield'],\n",
    "    'MI': ['Michigan', 'Lansing', 'Detroit', 'Grand Rapids'],\n",
    "    'MN': ['Minnesota', 'Saint Paul', 'Minneapolis', 'Rochester'],\n",
    "    'MS': ['Mississippi', 'Jackson', 'Gulfport', 'Southaven'],\n",
    "    'MO': ['Missouri', 'Jefferson City', 'Kansas City', 'St. Louis'],\n",
    "    'MT': ['Montana', 'Helena', 'Billings', 'Missoula'],\n",
    "    'NE': ['Nebraska', 'Lincoln', 'Omaha', 'Bellevue'],\n",
    "    'NV': ['Nevada', 'Carson City', 'Las Vegas', 'Henderson'],\n",
    "    'NH': ['New Hampshire', 'Concord', 'Manchester', 'Nashua'],\n",
    "    'NJ': ['New Jersey', 'Trenton', 'Newark', 'Jersey City'],\n",
    "    'NM': ['New Mexico', 'Santa Fe', 'Albuquerque', 'Las Cruces'],\n",
    "    'NY': ['New York', 'Albany', 'New York City', 'Buffalo'],\n",
    "    'NC': ['North Carolina', 'Raleigh', 'Charlotte', 'Greensboro'],\n",
    "    'ND': ['North Dakota', 'Bismarck', 'Fargo', 'Grand Forks'],\n",
    "    'OH': ['Ohio', 'Columbus', 'Cleveland', 'Cincinnati'],\n",
    "    'OK': ['Oklahoma', 'Oklahoma City', 'Tulsa', 'Norman'],\n",
    "    'OR': ['Oregon', 'Salem', 'Portland', 'Eugene'],\n",
    "    'PA': ['Pennsylvania', 'Harrisburg', 'Philadelphia', 'Pittsburgh'],\n",
    "    'RI': ['Rhode Island', 'Providence', 'Warwick', 'Cranston'],\n",
    "    'SC': ['South Carolina', 'Columbia', 'Charleston', 'North Charleston'],\n",
    "    'SD': ['South Dakota', 'Pierre', 'Sioux Falls', 'Rapid City'],\n",
    "    'TN': ['Tennessee', 'Nashville', 'Memphis', 'Knoxville'],\n",
    "    'TX': ['Texas', 'Austin', 'Houston', 'San Antonio'],\n",
    "    'UT': ['Utah', 'Salt Lake City', 'West Valley City', 'Provo'],\n",
    "    'VT': ['Vermont', 'Montpelier', 'Burlington', 'South Burlington'],\n",
    "    'VA': ['Virginia', 'Richmond', 'Virginia Beach', 'Norfolk'],\n",
    "    'WA': ['Washington', 'Olympia', 'Seattle', 'Spokane'],\n",
    "    'WV': ['West Virginia', 'Charleston', 'Huntington', 'Morgantown'],\n",
    "    'WI': ['Wisconsin', 'Madison', 'Milwaukee', 'Green Bay'],\n",
    "    'WY': ['Wyoming', 'Cheyenne', 'Casper', 'Laramie']\n",
    "}\n",
    "\n",
    "import ahocorasick\n",
    "\n",
    "A = ahocorasick.Automaton()\n",
    "for abbr, names in states_dict.items():\n",
    "    for name in names:\n",
    "        A.add_word(name.lower(), (name, abbr))\n",
    "A.make_automaton()\n",
    "\n",
    "def fast_extract_state(text):\n",
    "    text = str(text).lower()\n",
    "    found_states = set()\n",
    "\n",
    "    for _, (_, abbr) in A.iter(text):\n",
    "        found_states.add(abbr)\n",
    "\n",
    "    return list(found_states)\n",
    "\n",
    "df_filtered = df_filtered.with_columns(\n",
    "    pl.col(\"full_text\").map_elements(fast_extract_state, return_dtype=pl.List(pl.Utf8)).alias(\"state\")\n",
    ")\n",
    "\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe69a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_filtered.write_parquet(\"data/FILTERED_DATAFRAME_WITH_STATES.parquet\")\n",
    "# df_filtered = pl.read_parquet(\"data/FILTERED_DATAFRAME_WITH_STATES.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c953a7b7",
   "metadata": {},
   "source": [
    "## 2.2. Topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f164edb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>state</th><th>date</th><th>month_year</th><th>year</th><th>event_code</th><th>quad_class</th><th>goldstein_scale</th><th>avg_tone</th><th>actor1_statecode</th><th>actor2_statecode</th><th>url</th><th>title</th><th>full_text</th><th>topic_0</th><th>topic_1</th><th>topic_2</th><th>topic_3</th><th>topic_4</th><th>topic_5</th><th>topic_6</th><th>topic_7</th><th>topic_8</th><th>topic_9</th></tr><tr><td>list[str]</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>[&quot;WA&quot;, &quot;WI&quot;, … &quot;MA&quot;]</td><td>20210514</td><td>202105</td><td>2021</td><td>16</td><td>1</td><td>-2.0</td><td>-8.934073</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.natlawreview.com/a…</td><td>&quot;State of the Law for Business …</td><td>&quot;It’s been a year since COVID-1…</td><td>0.024562</td><td>0.000097</td><td>0.228645</td><td>0.187616</td><td>0.033062</td><td>0.000097</td><td>0.350562</td><td>0.003926</td><td>0.161016</td><td>0.010416</td></tr><tr><td>[&quot;KS&quot;, &quot;WA&quot;, &quot;MO&quot;]</td><td>20210514</td><td>202105</td><td>2021</td><td>141</td><td>3</td><td>-6.5</td><td>-0.808625</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.kcur.org/health/20…</td><td>&quot;Medicaid Expansion Supporters …</td><td>&quot;A day after Missouri Gov. Mike…</td><td>0.006544</td><td>0.098271</td><td>0.390895</td><td>0.132563</td><td>0.0219</td><td>0.152496</td><td>0.196633</td><td>0.000233</td><td>0.000233</td><td>0.000233</td></tr><tr><td>[&quot;NY&quot;, &quot;MO&quot;]</td><td>20210529</td><td>202105</td><td>2021</td><td>13</td><td>1</td><td>0.4</td><td>-6.008584</td><td>&quot;USMO&quot;</td><td>&quot;USMO&quot;</td><td>&quot;https://www.dailystar.co.uk/ne…</td><td>&quot;Elderly woman sucker-punched t…</td><td>&quot;Elderly woman sucker-punched t…</td><td>0.01934</td><td>0.000465</td><td>0.000465</td><td>0.000465</td><td>0.152191</td><td>0.123239</td><td>0.031558</td><td>0.000465</td><td>0.671346</td><td>0.000465</td></tr><tr><td>null</td><td>20200207</td><td>202002</td><td>2020</td><td>16</td><td>1</td><td>-2.0</td><td>-8.0</td><td>&quot;USAR&quot;</td><td>null</td><td>&quot;https://www.houstonchronicle.c…</td><td>null</td><td>null</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td><td>0.1</td></tr><tr><td>[&quot;NY&quot;, &quot;DE&quot;, … &quot;MA&quot;]</td><td>20201206</td><td>202012</td><td>2020</td><td>70</td><td>2</td><td>7.0</td><td>0.088106</td><td>&quot;USNH&quot;</td><td>&quot;USNH&quot;</td><td>&quot;https://www.fosters.com/story/…</td><td>&quot;Historically Speaking: Adventu…</td><td>&quot;Historically Speaking: Adventu…</td><td>0.005939</td><td>0.028983</td><td>0.190054</td><td>0.000172</td><td>0.389295</td><td>0.047708</td><td>0.010148</td><td>0.000172</td><td>0.126847</td><td>0.20068</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 23)\n",
       "┌────────────────┬──────────┬────────────┬──────┬───┬──────────┬──────────┬──────────┬──────────┐\n",
       "│ state          ┆ date     ┆ month_year ┆ year ┆ … ┆ topic_6  ┆ topic_7  ┆ topic_8  ┆ topic_9  │\n",
       "│ ---            ┆ ---      ┆ ---        ┆ ---  ┆   ┆ ---      ┆ ---      ┆ ---      ┆ ---      │\n",
       "│ list[str]      ┆ i64      ┆ i64        ┆ i64  ┆   ┆ f64      ┆ f64      ┆ f64      ┆ f64      │\n",
       "╞════════════════╪══════════╪════════════╪══════╪═══╪══════════╪══════════╪══════════╪══════════╡\n",
       "│ [\"WA\", \"WI\", … ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ 0.350562 ┆ 0.003926 ┆ 0.161016 ┆ 0.010416 │\n",
       "│ \"MA\"]          ┆          ┆            ┆      ┆   ┆          ┆          ┆          ┆          │\n",
       "│ [\"KS\", \"WA\",   ┆ 20210514 ┆ 202105     ┆ 2021 ┆ … ┆ 0.196633 ┆ 0.000233 ┆ 0.000233 ┆ 0.000233 │\n",
       "│ \"MO\"]          ┆          ┆            ┆      ┆   ┆          ┆          ┆          ┆          │\n",
       "│ [\"NY\", \"MO\"]   ┆ 20210529 ┆ 202105     ┆ 2021 ┆ … ┆ 0.031558 ┆ 0.000465 ┆ 0.671346 ┆ 0.000465 │\n",
       "│ null           ┆ 20200207 ┆ 202002     ┆ 2020 ┆ … ┆ 0.1      ┆ 0.1      ┆ 0.1      ┆ 0.1      │\n",
       "│ [\"NY\", \"DE\", … ┆ 20201206 ┆ 202012     ┆ 2020 ┆ … ┆ 0.010148 ┆ 0.000172 ┆ 0.126847 ┆ 0.20068  │\n",
       "│ \"MA\"]          ┆          ┆            ┆      ┆   ┆          ┆          ┆          ┆          │\n",
       "└────────────────┴──────────┴────────────┴──────┴───┴──────────┴──────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a clean texts series to deal with empty cells\n",
    "texts_clean = df_filtered.select(\n",
    "    pl.col('full_text').fill_null(\"\").cast(str)\n",
    ").to_series().to_list()\n",
    "\n",
    "# chunk generator - to apply LDA incrementally, for memory optimization\n",
    "def text_batch_generator(texts, batch_size):\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        yield texts[i:i + batch_size]\n",
    "\n",
    "# initialize vectorizer and LDA\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "vectorizer.fit(texts_clean)\n",
    "lda = LatentDirichletAllocation(n_components=10,\n",
    "                                learning_method='online',\n",
    "                                batch_size=100,\n",
    "                                random_state=42\n",
    "                                )\n",
    "\n",
    "# apply LDA by batches\n",
    "for batch_texts in text_batch_generator(texts_clean, batch_size=1000):\n",
    "    dtm_batch = vectorizer.transform(batch_texts)\n",
    "    lda.partial_fit(dtm_batch)\n",
    "\n",
    "# get topic distributions and add to the dataframe as new columns\n",
    "dtm_full = vectorizer.transform(texts_clean)\n",
    "topic_distributions = lda.transform(dtm_full)\n",
    "\n",
    "df_with_topics = df_filtered.with_columns(\n",
    "    [pl.Series(f\"topic_{i}\", topic_distributions[:, i]) for i in range(lda.n_components)]\n",
    ")\n",
    "\n",
    "df_with_topics.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a57352",
   "metadata": {},
   "source": [
    "## 2.3. Aggregating the data by month and state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4da14",
   "metadata": {},
   "source": [
    "Below we aggregate the data by month and state, for harmony with our terrorism panel. We obtain both the mean and the variance. An article is assigned to a state if that state was mentioned in its text (as per the list obtained on step 2.1).\n",
    "\n",
    "All the other columns get discarded. Other relevant columns have been processed in our *terrorism_processing.ipynb* and the text is not needed anymore. We also keep the state and period (year, month) columns as well as a joint column of state and period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c50eaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (900, 23)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>state</th><th>period</th><th>topic_0_mean</th><th>topic_1_mean</th><th>topic_2_mean</th><th>topic_3_mean</th><th>topic_4_mean</th><th>topic_5_mean</th><th>topic_6_mean</th><th>topic_7_mean</th><th>topic_8_mean</th><th>topic_9_mean</th><th>topic_0_var</th><th>topic_1_var</th><th>topic_2_var</th><th>topic_3_var</th><th>topic_4_var</th><th>topic_5_var</th><th>topic_6_var</th><th>topic_7_var</th><th>topic_8_var</th><th>topic_9_var</th><th>state_period</th></tr><tr><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;AK&quot;</td><td>202001</td><td>0.0062</td><td>0.176019</td><td>0.134228</td><td>0.046965</td><td>0.039173</td><td>0.165012</td><td>0.158361</td><td>0.000528</td><td>0.105847</td><td>0.167668</td><td>0.000382</td><td>0.08745</td><td>0.035572</td><td>0.014467</td><td>0.007535</td><td>0.019503</td><td>0.037005</td><td>0.000002</td><td>0.031942</td><td>0.043333</td><td>&quot;AK_202001&quot;</td></tr><tr><td>&quot;AK&quot;</td><td>202002</td><td>0.00614</td><td>0.229535</td><td>0.132027</td><td>0.035967</td><td>0.044017</td><td>0.150766</td><td>0.151576</td><td>0.000576</td><td>0.108995</td><td>0.140403</td><td>0.000292</td><td>0.115541</td><td>0.038064</td><td>0.008395</td><td>0.009673</td><td>0.021</td><td>0.039013</td><td>0.000003</td><td>0.043537</td><td>0.03494</td><td>&quot;AK_202002&quot;</td></tr><tr><td>&quot;AK&quot;</td><td>202003</td><td>0.009126</td><td>0.187728</td><td>0.129136</td><td>0.223781</td><td>0.028164</td><td>0.162057</td><td>0.056634</td><td>0.000504</td><td>0.060937</td><td>0.141933</td><td>0.000335</td><td>0.124263</td><td>0.028777</td><td>0.081757</td><td>0.00565</td><td>0.02526</td><td>0.010215</td><td>0.000002</td><td>0.024379</td><td>0.03561</td><td>&quot;AK_202003&quot;</td></tr><tr><td>&quot;AK&quot;</td><td>202004</td><td>0.008067</td><td>0.137361</td><td>0.15453</td><td>0.211661</td><td>0.023576</td><td>0.184967</td><td>0.076624</td><td>0.00598</td><td>0.047435</td><td>0.1498</td><td>0.000327</td><td>0.084534</td><td>0.035404</td><td>0.049256</td><td>0.00363</td><td>0.022603</td><td>0.010807</td><td>0.00519</td><td>0.013221</td><td>0.037571</td><td>&quot;AK_202004&quot;</td></tr><tr><td>&quot;AK&quot;</td><td>202005</td><td>0.014773</td><td>0.082678</td><td>0.156551</td><td>0.214141</td><td>0.033504</td><td>0.186337</td><td>0.096047</td><td>0.000531</td><td>0.065151</td><td>0.150287</td><td>0.001657</td><td>0.043889</td><td>0.036581</td><td>0.057899</td><td>0.004879</td><td>0.022767</td><td>0.018059</td><td>0.000002</td><td>0.017122</td><td>0.041323</td><td>&quot;AK_202005&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;WY&quot;</td><td>202102</td><td>0.006397</td><td>0.155883</td><td>0.13424</td><td>0.065846</td><td>0.042889</td><td>0.192026</td><td>0.178719</td><td>0.012297</td><td>0.10177</td><td>0.109931</td><td>0.000282</td><td>0.039414</td><td>0.032426</td><td>0.033008</td><td>0.008681</td><td>0.016387</td><td>0.031606</td><td>0.011174</td><td>0.039751</td><td>0.021688</td><td>&quot;WY_202102&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>202103</td><td>0.010679</td><td>0.10315</td><td>0.173409</td><td>0.100278</td><td>0.035296</td><td>0.195375</td><td>0.145272</td><td>0.021006</td><td>0.093479</td><td>0.122054</td><td>0.00165</td><td>0.020322</td><td>0.029198</td><td>0.036147</td><td>0.007616</td><td>0.018053</td><td>0.01978</td><td>0.019312</td><td>0.030987</td><td>0.026692</td><td>&quot;WY_202103&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>202104</td><td>0.010255</td><td>0.075212</td><td>0.16735</td><td>0.10578</td><td>0.048858</td><td>0.196286</td><td>0.12088</td><td>0.012154</td><td>0.107896</td><td>0.155328</td><td>0.000507</td><td>0.020575</td><td>0.036652</td><td>0.046952</td><td>0.010197</td><td>0.017927</td><td>0.023781</td><td>0.01042</td><td>0.040783</td><td>0.03577</td><td>&quot;WY_202104&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>202105</td><td>0.008317</td><td>0.17187</td><td>0.133395</td><td>0.073182</td><td>0.039383</td><td>0.201833</td><td>0.184163</td><td>0.000526</td><td>0.090838</td><td>0.096494</td><td>0.000445</td><td>0.04347</td><td>0.027583</td><td>0.031676</td><td>0.007761</td><td>0.017987</td><td>0.026985</td><td>0.000002</td><td>0.024357</td><td>0.022534</td><td>&quot;WY_202105&quot;</td></tr><tr><td>&quot;WY&quot;</td><td>202106</td><td>0.010294</td><td>0.068541</td><td>0.13863</td><td>0.095888</td><td>0.048711</td><td>0.222224</td><td>0.124157</td><td>0.011541</td><td>0.096993</td><td>0.183021</td><td>0.000468</td><td>0.018619</td><td>0.025453</td><td>0.042031</td><td>0.007291</td><td>0.020141</td><td>0.022773</td><td>0.010345</td><td>0.032195</td><td>0.036056</td><td>&quot;WY_202106&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (900, 23)\n",
       "┌───────┬────────┬────────────┬────────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ state ┆ period ┆ topic_0_me ┆ topic_1_me ┆ … ┆ topic_7_va ┆ topic_8_va ┆ topic_9_va ┆ state_peri │\n",
       "│ ---   ┆ ---    ┆ an         ┆ an         ┆   ┆ r          ┆ r          ┆ r          ┆ od         │\n",
       "│ str   ┆ i64    ┆ ---        ┆ ---        ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│       ┆        ┆ f64        ┆ f64        ┆   ┆ f64        ┆ f64        ┆ f64        ┆ str        │\n",
       "╞═══════╪════════╪════════════╪════════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ AK    ┆ 202001 ┆ 0.0062     ┆ 0.176019   ┆ … ┆ 0.000002   ┆ 0.031942   ┆ 0.043333   ┆ AK_202001  │\n",
       "│ AK    ┆ 202002 ┆ 0.00614    ┆ 0.229535   ┆ … ┆ 0.000003   ┆ 0.043537   ┆ 0.03494    ┆ AK_202002  │\n",
       "│ AK    ┆ 202003 ┆ 0.009126   ┆ 0.187728   ┆ … ┆ 0.000002   ┆ 0.024379   ┆ 0.03561    ┆ AK_202003  │\n",
       "│ AK    ┆ 202004 ┆ 0.008067   ┆ 0.137361   ┆ … ┆ 0.00519    ┆ 0.013221   ┆ 0.037571   ┆ AK_202004  │\n",
       "│ AK    ┆ 202005 ┆ 0.014773   ┆ 0.082678   ┆ … ┆ 0.000002   ┆ 0.017122   ┆ 0.041323   ┆ AK_202005  │\n",
       "│ …     ┆ …      ┆ …          ┆ …          ┆ … ┆ …          ┆ …          ┆ …          ┆ …          │\n",
       "│ WY    ┆ 202102 ┆ 0.006397   ┆ 0.155883   ┆ … ┆ 0.011174   ┆ 0.039751   ┆ 0.021688   ┆ WY_202102  │\n",
       "│ WY    ┆ 202103 ┆ 0.010679   ┆ 0.10315    ┆ … ┆ 0.019312   ┆ 0.030987   ┆ 0.026692   ┆ WY_202103  │\n",
       "│ WY    ┆ 202104 ┆ 0.010255   ┆ 0.075212   ┆ … ┆ 0.01042    ┆ 0.040783   ┆ 0.03577    ┆ WY_202104  │\n",
       "│ WY    ┆ 202105 ┆ 0.008317   ┆ 0.17187    ┆ … ┆ 0.000002   ┆ 0.024357   ┆ 0.022534   ┆ WY_202105  │\n",
       "│ WY    ┆ 202106 ┆ 0.010294   ┆ 0.068541   ┆ … ┆ 0.010345   ┆ 0.032195   ┆ 0.036056   ┆ WY_202106  │\n",
       "└───────┴────────┴────────────┴────────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select topic columns\n",
    "topic_cols = [f'topic_{i}' for i in range(10)]\n",
    "\n",
    "df_aggregated = (\n",
    "    df_with_topics\n",
    "    .filter(pl.col('title').is_not_null())\n",
    "    .with_columns(\n",
    "        (pl.col('date') // 100).alias('period')\n",
    "    )\n",
    "    .explode('state')\n",
    "    .filter(pl.col('state').is_not_null())\n",
    "    # do group_by and obtain mean and variance\n",
    "    .group_by(['state', 'period'])\n",
    "    .agg([\n",
    "        *[pl.col(topic).mean().alias(f'{topic}_mean') for topic in topic_cols],\n",
    "        *[pl.col(topic).var().alias(f'{topic}_var') for topic in topic_cols],\n",
    "    ])\n",
    "    .with_columns(\n",
    "        (pl.col('state') + \"_\" + pl.col('period').cast(pl.Utf8)).alias('state_period')\n",
    "    )\n",
    "    .sort('state_period')\n",
    ")\n",
    "\n",
    "df_aggregated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6c570bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated.write_parquet(\"data/AGGREGATED_DATAFRAME.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
